{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Libraries and Set Up"
      ],
      "metadata": {
        "id": "p5CGDls4T3Oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "aUeAIS_vUaAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights -O yolov3.weights\n",
        "!wget https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg -O yolov3.cfg\n",
        "!wget https://github.com/pjreddie/darknet/blob/master/data/coco.names -O coco.names\n",
        "!ls -lh yolov3.weights yolov3.cfg coco.names"
      ],
      "metadata": {
        "id": "WlLDXwltWZI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/pjreddie/darknet/raw/master/cfg/yolov3.cfg -O yolov3.cfg"
      ],
      "metadata": {
        "id": "MxFaEoBRbm9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsUZecmyT2e7"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Vehicle Detection Script"
      ],
      "metadata": {
        "id": "KQd1xY8OT7vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Vehicle Detection\n",
        "\n",
        "# Load YOLO pre-trained model for vehicle detection\n",
        "net = cv2.dnn.readNet(\"/content/yolov3.weights\", \"/content/yolov3.cfg\")\n",
        "\n",
        "# Load the COCO names file (contains class names)\n",
        "classes = []\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = f.read().strip().split(\"\\n\")\n",
        "\n",
        "# Load the image\n",
        "image_path = \"/content/car1.jpeg\"  # Ensure this image is uploaded\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Get image dimensions\n",
        "height, width, _ = image.shape\n",
        "\n",
        "# Preprocess the image for YOLO\n",
        "blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "# Set input blob for the network\n",
        "net.setInput(blob)\n",
        "\n",
        "# Get output layer names\n",
        "output_layers = net.getUnconnectedOutLayersNames()\n",
        "\n",
        "# Perform forward pass and get detections\n",
        "detections = net.forward(output_layers)\n",
        "\n",
        "# Loop through detections\n",
        "for detection in detections:\n",
        "    for obj in detection:\n",
        "        scores = obj[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "\n",
        "        if confidence > 0.5 and class_id == 2:  # Class ID for cars is 2\n",
        "            center_x = int(obj[0] * width)\n",
        "            center_y = int(obj[1] * height)\n",
        "            w = int(obj[2] * width)\n",
        "            h = int(obj[3] * height)\n",
        "\n",
        "            x = int(center_x - w / 2)\n",
        "            y = int(center_y - h / 2)\n",
        "\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(image, \"Vehicle\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Display the image with detections\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "Ub6H-yXIT-vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Vehicle Detection\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load YOLO pre-trained model for vehicle detection\n",
        "net = cv2.dnn.readNet(\"/content/yolov3.weights\", \"/content/yolov3.cfg\")\n",
        "\n",
        "# Load the COCO names file (contains class names)\n",
        "classes = []\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = f.read().strip().split(\"\\n\")\n",
        "\n",
        "# Load the image\n",
        "image_path = \"/content/car1.jpeg\"  # Ensure this image is uploaded\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Get image dimensions\n",
        "height, width, _ = image.shape\n",
        "\n",
        "# Preprocess the image for YOLO\n",
        "blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "# Set input blob for the network\n",
        "net.setInput(blob)\n",
        "\n",
        "# Get output layer names\n",
        "output_layers = net.getUnconnectedOutLayersNames()\n",
        "\n",
        "# Perform forward pass and get detections\n",
        "detections = net.forward(output_layers)\n",
        "\n",
        "# Initialize lists for bounding boxes, confidences, and class IDs\n",
        "boxes = []\n",
        "confidences = []\n",
        "class_ids = []\n",
        "\n",
        "# Loop through detections\n",
        "for detection in detections:\n",
        "    for obj in detection:\n",
        "        scores = obj[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "\n",
        "        if confidence > 0.5 and class_id == 2:  # Class ID for cars is 2\n",
        "            center_x = int(obj[0] * width)\n",
        "            center_y = int(obj[1] * height)\n",
        "            w = int(obj[2] * width)\n",
        "            h = int(obj[3] * height)\n",
        "\n",
        "            x = int(center_x - w / 2)\n",
        "            y = int(center_y - h / 2)\n",
        "\n",
        "            # Add to lists\n",
        "            boxes.append([x, y, w, h])\n",
        "            confidences.append(float(confidence))\n",
        "            class_ids.append(class_id)\n",
        "\n",
        "# Apply Non-Maximum Suppression to remove overlapping bounding boxes\n",
        "indices = cv2.dnn.NMSBoxes(boxes, confidences, score_threshold=0.5, nms_threshold=0.4)\n",
        "\n",
        "# Draw bounding boxes for detections that are kept after NMS\n",
        "for i in indices.flatten():\n",
        "    x, y, w, h = boxes[i]\n",
        "    label = str(classes[class_ids[i]])\n",
        "    confidence = confidences[i]\n",
        "\n",
        "    # Draw rectangle around detected car\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "    cv2.putText(image, f\"{label} {confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Display the image with detections\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "MufXmeMnOIpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Capture Image Script"
      ],
      "metadata": {
        "id": "soInBuikUHXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Capture Image\n",
        "\n",
        "def capture_image(camera_index, output_path):\n",
        "    # Open the camera\n",
        "    cap = cv2.VideoCapture(camera_index)\n",
        "\n",
        "    # Check if the camera opened successfully\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open camera.\")\n",
        "        return\n",
        "\n",
        "    # Read a frame from the camera\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if the frame was read successfully\n",
        "    if not ret:\n",
        "        print(\"Error: Could not read frame from camera.\")\n",
        "        return\n",
        "\n",
        "    # Save the captured frame as an image\n",
        "    cv2.imwrite(output_path, frame)\n",
        "\n",
        "    # Release the camera\n",
        "    cap.release()\n",
        "    print(\"Image captured and saved as\", output_path)\n",
        "\n",
        "def main_capture():\n",
        "    camera_index = 0  # Change this to the appropriate camera index\n",
        "    interval_seconds = 5  # Time interval between captures\n",
        "\n",
        "    for _ in range(3):  # Capture 3 images for demonstration\n",
        "        timestamp = time.strftime(\"%Y%m%d%H%M%S\")\n",
        "        image_filename = f\"captured_image_{timestamp}.jpg\"\n",
        "\n",
        "        capture_image(camera_index, image_filename)\n",
        "        time.sleep(interval_seconds)\n",
        "\n",
        "main_capture()\n"
      ],
      "metadata": {
        "id": "w1owrHYRUK78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Adjust Green Signal Time Script"
      ],
      "metadata": {
        "id": "1pQgwlXXUMqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Adjust Green Signal Time\n",
        "\n",
        "def adjust_green_signal_time(vehicle_count):\n",
        "    base_green_time = 30  # Base green time in seconds\n",
        "    vehicle_multiplier = 2  # Green time increases by 2 seconds per vehicle\n",
        "\n",
        "    green_time = base_green_time + (vehicle_count * vehicle_multiplier)\n",
        "    return green_time\n",
        "\n",
        "def main_adjust():\n",
        "    try:\n",
        "        with open(\"vehicle_count.txt\", \"r\") as file:\n",
        "            vehicle_count = int(file.read())\n",
        "\n",
        "            if vehicle_count < 0:\n",
        "                print(\"Invalid vehicle count in the file. Please ensure the count is a non-negative integer.\")\n",
        "                return\n",
        "\n",
        "        green_time = adjust_green_signal_time(vehicle_count)\n",
        "        print(\"Adjusted Green Signal Time:\", green_time, \"seconds\")\n",
        "    except (ValueError, FileNotFoundError):\n",
        "        print(\"Error reading vehicle count from file.\")\n",
        "\n",
        "main_adjust()\n"
      ],
      "metadata": {
        "id": "_SFWYfKKUSEb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}