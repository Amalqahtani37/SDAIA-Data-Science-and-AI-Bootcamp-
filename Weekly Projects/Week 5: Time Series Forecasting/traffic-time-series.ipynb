{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Flask"
      ],
      "metadata": {
        "id": "VkcqqBaVbjq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "FLKw3jZuh4Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo"
      ],
      "metadata": {
        "id": "HGg2JbLLiPG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and read dataset\n",
        "import opendatasets as od\n",
        "dataset = 'https://www.kaggle.com/datasets/stealthtechnologies/traffic-time-series-dataset/data'\n",
        "od.download(dataset)"
      ],
      "metadata": {
        "id": "IvHcXr8fh1q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example dataset\n",
        "df = pd.read_csv('/content/traffic-time-series-dataset/traffic_dataset_with_trend.csv', parse_dates=['Timestamp'])"
      ],
      "metadata": {
        "id": "A6V1D9cIU-SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Database Integration**"
      ],
      "metadata": {
        "id": "GWna_BgD-mhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "import gridfs\n",
        "client = MongoClient('mongodb+srv://smuhaini98:LcN514QQgB3rxOZX@cluster0.jy02b.mongodb.net/')\n",
        "\n",
        "\n",
        "database_name = 'Cluster0'\n",
        "db = client[database_name]\n",
        "fs = gridfs.GridFS(db)"
      ],
      "metadata": {
        "id": "91H_zA_kiT3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection = db['Cluster0']"
      ],
      "metadata": {
        "id": "VubFS4FWiXq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "\n",
        "uri = 'mongodb+srv://smuhaini98:LcN514QQgB3rxOZX@cluster0.jy02b.mongodb.net/'\n",
        "\n",
        "client = MongoClient(uri)\n",
        "\n",
        "\n",
        "db = client['Traffic']\n",
        "\n",
        "# Access a collection\n",
        "collection = db['TrafficTime']"
      ],
      "metadata": {
        "id": "29T4X-U1iq_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query\n",
        "result = collection.find_one()\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Ey9546boi3HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/traffic-time-series-dataset/traffic_dataset_with_trend.csv'"
      ],
      "metadata": {
        "id": "qwbG7Iz6-LAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_path, 'rb') as file:\n",
        "    file_id = fs.put(file, filename='file.zip')\n",
        "    print(f\"File stored with file ID: {file_id}\")"
      ],
      "metadata": {
        "id": "vie1XIbh-OnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stored_file = fs.get(file_id)\n",
        "print(f\"Retrieved file: {stored_file.filename}, Size: {stored_file.length} bytes\")"
      ],
      "metadata": {
        "id": "ElIfQHRP-TXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_path = '/content/detect.zip'\n",
        "\n",
        "retrieved_file = fs.get(file_id)\n",
        "\n",
        "with open(output_file_path, 'wb') as file:\n",
        "    file.write(retrieved_file.read())\n",
        "\n",
        "print(f\"File retrieved and saved as: {output_file_path}\")"
      ],
      "metadata": {
        "id": "6NFIso1C-VsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EDA**"
      ],
      "metadata": {
        "id": "4gqR-v3__sfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "zWum6rO9UVdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "3VBtwfoWUvas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "wqCd0eX2UzPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "2O8xH1TiU14k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "p8eh0sc8VLzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "FgIqQGpyVPAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "83rGb0oVVRkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "q9P2WOjjVWAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract time features\n",
        "df['Hour'] = df['Timestamp'].dt.hour\n",
        "df['DayOfWeek'] = df['Timestamp'].dt.dayofweek\n",
        "df['Month'] = df['Timestamp'].dt.month"
      ],
      "metadata": {
        "id": "5xz0eItaX395"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(figsize=(15, 10))"
      ],
      "metadata": {
        "id": "IbbjGSuwZHJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only numeric columns for correlation calculation\n",
        "numeric_df = df.select_dtypes(include=['number'])\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "corr_matrix = numeric_df.corr()\n",
        "\n",
        "corr_matrix"
      ],
      "metadata": {
        "id": "eyb9zbhMZ4Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix.style.background_gradient(cmap='coolwarm')"
      ],
      "metadata": {
        "id": "GTFfYRvlaFbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Month'].unique()"
      ],
      "metadata": {
        "id": "LlgK6JSWVm0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Weather'].unique()"
      ],
      "metadata": {
        "id": "ICUPWYK2VZcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Events'].unique()"
      ],
      "metadata": {
        "id": "ixlTUBeKVei3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Hour'].unique()"
      ],
      "metadata": {
        "id": "zwacfWfcV5XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode weather data\n",
        "weather_encoder = OneHotEncoder(sparse=False)\n",
        "weather_encoded = weather_encoder.fit_transform(df[['Weather']])"
      ],
      "metadata": {
        "id": "7DVG8vUEX9kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocessing**"
      ],
      "metadata": {
        "id": "smbT6e2iBV2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weather_encoder"
      ],
      "metadata": {
        "id": "ZgRAzQ-_YGEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_encoded"
      ],
      "metadata": {
        "id": "Jdp0oKSZYeFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate weather features and time features\n",
        "features = np.hstack((df[['Hour', 'DayOfWeek', 'Month']].values, weather_encoded))\n",
        "features"
      ],
      "metadata": {
        "id": "---4gl7wX9XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Traffic volume target\n",
        "target = df['Traffic Volume'].values\n",
        "target"
      ],
      "metadata": {
        "id": "O8vmpLkIYl8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features\n",
        "feature_scaler = MinMaxScaler()\n",
        "scaled_features = feature_scaler.fit_transform(features)\n",
        "\n",
        "# Scale target\n",
        "target_scaler = MinMaxScaler()\n",
        "scaled_target = target_scaler.fit_transform(target.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "_ISSKlkCYuqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Split Data**"
      ],
      "metadata": {
        "id": "_Hoe9nNcAeK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare sequences\n",
        "def create_sequences(features, target, n_past):\n",
        "    X, y = [], []\n",
        "    for i in range(n_past, len(features)):\n",
        "        X.append(features[i - n_past:i])\n",
        "        y.append(target[i])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "7mlN4cJxiDFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X and y here\n",
        "n_past = 60\n",
        "X, y = create_sequences(scaled_features, scaled_target, n_past)"
      ],
      "metadata": {
        "id": "EtkCypTRY2za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Selection**"
      ],
      "metadata": {
        "id": "sGXGKHtbArdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model architecture\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(X.shape[1], X.shape[2]))) # Now X is defined\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "DRoifT8EY4PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "id": "gnzprq2iY7cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set (split data accordingly)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)\n",
        "\n",
        "# Inverse transform to original scale\n",
        "train_predict = target_scaler.inverse_transform(train_predict)\n",
        "y_train = target_scaler.inverse_transform(y_train)\n",
        "test_predict = target_scaler.inverse_transform(test_predict)\n",
        "y_test = target_scaler.inverse_transform(y_test)"
      ],
      "metadata": {
        "id": "PgwOC5Ijdto5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "# Calculate performance metrics\n",
        "train_mae = mean_absolute_error(y_train, train_predict)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, train_predict))\n",
        "test_mae = mean_absolute_error(y_test, test_predict)\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, test_predict))\n",
        "test_r2 = r2_score(y_test, test_predict)\n",
        "\n",
        "print(f'Training MAE: {train_mae:.2f}')\n",
        "print(f'Training RMSE: {train_rmse:.2f}')\n",
        "print(f'Test MAE: {test_mae:.2f}')\n",
        "print(f'Test RMSE: {test_rmse:.2f}')\n",
        "print(f'Test R-squared: {test_r2:.2f}')"
      ],
      "metadata": {
        "id": "kIF9zUkPw4W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting train predictions\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(y_train, label='True Values (Train)')\n",
        "plt.plot(train_predict, label='Predicted Values (Train)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting test predictions\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(y_test, label='True Values (Test)')\n",
        "plt.plot(test_predict, label='Predicted Values (Test)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7cwlVczpdvwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('lstm_traffic_model.h5')"
      ],
      "metadata": {
        "id": "t6kDjiZDQcb_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}